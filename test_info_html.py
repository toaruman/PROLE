import requests
from bs4 import BeautifulSoup
import re

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
}

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®URL
test_url = "https://www.rakuten.co.jp/pelote/info.html"

print(f"ğŸ” ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {test_url}")
try:
    r = requests.get(test_url, headers=HEADERS, timeout=15)
    r.encoding = 'euc-jp'  # â† æ˜ç¤ºçš„ã«æ–‡å­—ã‚³ãƒ¼ãƒ‰æŒ‡å®š
    r.raise_for_status()
    soup = BeautifulSoup(r.text, 'html.parser')
    print("âœ… HTMLå–å¾— & ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")

    dl_tag = soup.find("dl")
    if dl_tag:
        print("âœ… <dl> ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        dt_tags = dl_tag.find_all("dt")
        for i, dt in enumerate(dt_tags[:5]):  # ä¸Šä½5å€‹ã¾ã§
            print(f"ğŸ“¦ dt[{i}] = {dt.get_text(' ', strip=True)}")
    else:
        print("âŒ <dl> ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
